{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data_preprocessed = pd.read_csv('../data/preprocessed_data/TelcoCustomerChurn_Preprocessed.csv')\n",
    "\n",
    "feature_names = data_preprocessed.columns.tolist()\n",
    "feature_names.remove('Churn')\n",
    "feature_names.remove('CustomerID')\n",
    "\n",
    "data_preprocessed.set_index('CustomerID', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_preprocessed.drop(columns=['Churn']),  # Features (excluding the target variable)\n",
    "    data_preprocessed['Churn'],  # Target variable\n",
    "    test_size=0.25,  # 25% of data used for testing\n",
    "    random_state=42,  # Ensures reproducibility\n",
    "    stratify=data_preprocessed['Churn']  # Maintains distribution of target variable\n",
    ")\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "X_test.to_csv('../data/test_data/X_test.csv')\n",
    "y_test.to_csv('../data/test_data/y_test.csv')\n",
    "\n",
    "# Predict the probabilities on the testing set\n",
    "y_test_probabilities = logreg_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "roc_auc = roc_auc_score(y_test, y_test_probabilities)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_probabilities)\n",
    "\n",
    "#Display ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'Logistic Regression (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Display ROC AUC score\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': np.logspace(-3, 3, 7),  # Regularization parameter\n",
    "    'penalty': ['l1', 'l2'],  # Regularization type\n",
    "    'max_iter': [100, 200, 300, 400, 500],  # Max iterations for solver\n",
    "    'solver': ['liblinear', 'saga']  # Solvers that can handle both L1 and L2 regularization\n",
    "}\n",
    "\n",
    "# Initialize a Logistic Regression model\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    logreg_model,  # Model to be tuned\n",
    "    param_grid,  # Hyperparameter options\n",
    "    scoring='roc_auc',  # Evaluation metric\n",
    "    cv=5,  # Cross-validation folds\n",
    "    verbose=1,  # Output search results\n",
    "    n_jobs=-1  # Use all available processors\n",
    ")\n",
    "\n",
    "# Perform Grid Search on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "    \n",
    "# Retrieve the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the Logistic Regression model with the optimal hyperparameters\n",
    "logreg_model_optimized = LogisticRegression(\n",
    "    C=10.0, \n",
    "    max_iter=100, \n",
    "    penalty='l2', \n",
    "    solver='saga', \n",
    "    random_state=42\n",
    ")\n",
    "logreg_model_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature importances (coefficients) from the model\n",
    "coefficients = logreg_model_optimized.coef_.flatten()\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': coefficients\n",
    "})\n",
    "\n",
    "# Sort the features by absolute importance\n",
    "feature_importance['Abs_Importance'] = feature_importance['Importance'].abs()\n",
    "feature_importance = feature_importance.sort_values(by='Abs_Importance', ascending=False).drop(columns='Abs_Importance')\n",
    "feature_importance['Importance'] = feature_importance['Importance'].apply(lambda x: abs(x))\n",
    "\n",
    "# Display top 10 features\n",
    "feature_importance.to_csv('../data/preprocessed_data/feature_importance.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = '../models/mlModel.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(logreg_model_optimized, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
